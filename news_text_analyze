import numpy as np
import pandas as pd
import os
import gc
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tqdm import tqdm

train=pd.read_csv('train.csv')
test=pd.read_csv('test.csv')
submission=pd.read_csv('sample_submission.csv')

train['full_log'].str.split(' ').str.len().hist(bins=50)

train['full_log']=train['full_log'].str.replace(r'[0-9]', '<num>')
test['full_log']=test['full_log'].str.replace(r'[0-9]', '<num>')

train_text=list(train['full_log'])
train_level=np.array(train['level'])

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vect = TfidfVectorizer(analyzer="word", max_features=10000)????????????????
vectorizer=CountVectorizer(analyzer="word", max_features=10000)

train_features=vectorizer.fit_transform(train_text)
train_features1=tfidf_vect.fit_transform(train_text)

test_text=list(test['full_log'])
ids=list(test['id'])

test_features=vectorizer.transform(test_text)
test_features1=tfidf_vect.transform(test_text)

#랜덤 포레스트로 학습
from sklearn.ensemble import RandomForestClassifier
forest=RandomForestClassifier(n_estimators=100)

forest.fit(train_features,train_level)

results=forest.predict(test_features)
results_proba=forest.predict_proba(test_features)
results[np.where(np.max(results_proba, axis=1) < 0.9)] = 7

submission['level']=results
submission.to_csv('baseline_submission.csv', index=False)

#XGB로 학습(이게 가장 베스트)
from xgboost import XGBClassifier
xgb_wrapper = XGBClassifier()

xgb_wrapper.fit(train_features,train_level)
results=xgb_wrapper.predict(test_features)
results_proba=xgb_wrapper.predict_proba(test_features)
results[np.where(np.max(results_proba, axis=1) < 0.9)] = 7

submission['level']=results
submission.to_csv('baseline_submission4.csv', index=False)
